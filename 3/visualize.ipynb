{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from models import PNet\n",
    "from dataset import FaceDataset\n",
    "from utils import *\n",
    "\n",
    "from models import *\n",
    "from detect_utils import *\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "pnet = PNet()\n",
    "if cuda:\n",
    "    pnet = pnet.cuda()\n",
    "checkpoint = torch.load(\"pnet.pth.tar\")\n",
    "pnet.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# You should train these models\n",
    "\n",
    "# rnet = RNet()\n",
    "# if cuda:\n",
    "#     rnet = pnet.cuda()\n",
    "# checkpoint = torch.load(\"model_best_rnet.pth.tar\")\n",
    "# rnet.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# onet = ONet()\n",
    "# if cuda:\n",
    "#     onet = onet.cuda()\n",
    "# checkpoint = torch.load(\"model_best_onet.pth.tar\")\n",
    "# onet.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./img.jpg')\n",
    "detectors = [pnet, None, None]\n",
    "bounding_boxes = detect_faces(detectors, img)\n",
    "res = show_bboxes(img, bounding_boxes)\n",
    "cv2.imwrite(\"res.jpg\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
